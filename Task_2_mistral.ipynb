{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e69c185fdad246fb971539f1c8456073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_0cdb404b5641431195214ae5f1b248aa"
          }
        },
        "e7fcb46aaf814a798f74896332c967d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_827a6f6c02b94802a6b66b514a8d183b",
            "placeholder": "​",
            "style": "IPY_MODEL_2dce9e6c942543dea08c88baffb8e33c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "f9488fa92ae448979a75fdfc99bf9e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ad5a918f0b814f0d8551f4adf80424d3",
            "placeholder": "​",
            "style": "IPY_MODEL_f35986a6f61d4ce0b84119f4956df8e8",
            "value": ""
          }
        },
        "259dcc67ce594ecc899a49fca0758752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_5d2429714d934c22a959f4e4cd5c90c3",
            "style": "IPY_MODEL_5c9e4f54121049529b45778cebfeae14",
            "value": true
          }
        },
        "111173be2919418c860a0cb2c7d69ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b3e044def1a04d54b6b167240387277e",
            "style": "IPY_MODEL_e3577902489a455eb0d8aeaf48bd1e03",
            "tooltip": ""
          }
        },
        "bb6e3d7300d247f3b39e3ec1c858d306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abda9d153504499bb3168ac6ed78c163",
            "placeholder": "​",
            "style": "IPY_MODEL_eae49bba051d45c8aeed5b2c16d3b3b3",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "0cdb404b5641431195214ae5f1b248aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "827a6f6c02b94802a6b66b514a8d183b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dce9e6c942543dea08c88baffb8e33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5a918f0b814f0d8551f4adf80424d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35986a6f61d4ce0b84119f4956df8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2429714d934c22a959f4e4cd5c90c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9e4f54121049529b45778cebfeae14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3e044def1a04d54b6b167240387277e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3577902489a455eb0d8aeaf48bd1e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "abda9d153504499bb3168ac6ed78c163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eae49bba051d45c8aeed5b2c16d3b3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9729451f26834dd081a47c263b974927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7714109864454ac3aa28858cee7e7821",
            "placeholder": "​",
            "style": "IPY_MODEL_6c4d9ca6ea5a429ca4ea50c8bf1c4b02",
            "value": "Connecting..."
          }
        },
        "7714109864454ac3aa28858cee7e7821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4d9ca6ea5a429ca4ea50c8bf1c4b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()  # This will prompt you to enter the token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "e69c185fdad246fb971539f1c8456073",
            "e7fcb46aaf814a798f74896332c967d6",
            "f9488fa92ae448979a75fdfc99bf9e23",
            "259dcc67ce594ecc899a49fca0758752",
            "111173be2919418c860a0cb2c7d69ca7",
            "bb6e3d7300d247f3b39e3ec1c858d306",
            "0cdb404b5641431195214ae5f1b248aa",
            "827a6f6c02b94802a6b66b514a8d183b",
            "2dce9e6c942543dea08c88baffb8e33c",
            "ad5a918f0b814f0d8551f4adf80424d3",
            "f35986a6f61d4ce0b84119f4956df8e8",
            "5d2429714d934c22a959f4e4cd5c90c3",
            "5c9e4f54121049529b45778cebfeae14",
            "b3e044def1a04d54b6b167240387277e",
            "e3577902489a455eb0d8aeaf48bd1e03",
            "abda9d153504499bb3168ac6ed78c163",
            "eae49bba051d45c8aeed5b2c16d3b3b3",
            "9729451f26834dd081a47c263b974927",
            "7714109864454ac3aa28858cee7e7821",
            "6c4d9ca6ea5a429ca4ea50c8bf1c4b02"
          ]
        },
        "id": "rONlcB5K35SG",
        "outputId": "07009f78-722f-4d93-801d-29eb61fd2018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e69c185fdad246fb971539f1c8456073"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoModelForTokenClassification,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from collections import defaultdict\n",
        "\n",
        "# Configuration with 4-bit quantization\n",
        "MODEL_CONFIGS = {\n",
        "    \"mistral-7b\": {\n",
        "        \"name\": \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "        \"max_length\": 512,  # Use longer context\n",
        "        \"batch_size\": 2,    # Reduced for VRAM\n",
        "        \"lora_r\": 16,       # LoRA parameters\n",
        "        \"lora_alpha\": 32\n",
        "    }\n",
        "}\n",
        "\n",
        "# 4-bit quantization config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=MODEL_CONFIGS[\"mistral-7b\"][\"lora_r\"],\n",
        "    lora_alpha=MODEL_CONFIGS[\"mistral-7b\"][\"lora_alpha\"],\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    task_type=\"TOKEN_CLS\",\n",
        "    inference_mode=False\n",
        ")\n",
        "\n",
        "class MistralSpanDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.input_ids = encodings[\"input_ids\"]\n",
        "        self.attention_mask = encodings[\"attention_mask\"]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_mask[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "def load_model_and_tokenizer(config):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        config[\"name\"],\n",
        "        padding_side=\"right\",\n",
        "        add_prefix_space=True\n",
        "    )\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        config[\"name\"],\n",
        "        num_labels=len(label_map),\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        problem_type=\"multi_label_classification\"\n",
        "    )\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def mistral_collate_fn(batch):\n",
        "    return {\n",
        "        'input_ids': torch.stack([x['input_ids'] for x in batch]),\n",
        "        'attention_mask': torch.stack([x['attention_mask'] for x in batch]),\n",
        "        'labels': torch.stack([x['labels'] for x in batch])\n",
        "\n",
        "    }\n",
        "\n",
        "def convert_spans_to_token_labels(text, spans, offset_mapping, max_length, label_map):\n",
        "    \"\"\"\n",
        "    Converts character-level spans to token-level multi-label classification tags.\n",
        "    Returns a tensor of shape [max_length, num_labels] with binary labels.\n",
        "    \"\"\"\n",
        "    num_labels = len(label_map)\n",
        "    labels = np.zeros((max_length, num_labels), dtype=np.float32)\n",
        "\n",
        "    for span in spans:\n",
        "        technique = span[\"technique\"]\n",
        "        start_char = span[\"start\"]\n",
        "        end_char = span[\"end\"]\n",
        "        label_idx = label_map[technique]\n",
        "\n",
        "        # Find tokens overlapping with the span\n",
        "        for token_idx, (token_start, token_end) in enumerate(offset_mapping):\n",
        "            if token_idx >= max_length:\n",
        "                break  # Skip truncated tokens\n",
        "\n",
        "            # Check token overlap with span\n",
        "            if (token_start < end_char) and (token_end > start_char):\n",
        "                labels[token_idx, label_idx] = 1.0\n",
        "\n",
        "    return labels\n",
        "\n",
        "def optimize_thresholds(probs, labels, label_map):\n",
        "    \"\"\"\n",
        "    Finds the optimal threshold for each class by maximizing F1 score.\n",
        "    Returns a dictionary mapping class index -> optimal threshold.\n",
        "    \"\"\"\n",
        "    best_thresholds = {}\n",
        "    for i in range(len(label_map)):\n",
        "        best_f1 = 0.0\n",
        "        best_thresh = 0.5\n",
        "        for thresh in np.arange(0.1, 0.9, 0.05):\n",
        "            pred = (probs[:, :, i] > thresh).astype(int)\n",
        "            f1 = f1_score(labels[:, :, i].flatten(), pred.flatten(), zero_division=0)\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresh = thresh\n",
        "        best_thresholds[i] = best_thresh\n",
        "    return best_thresholds\n",
        "\n",
        "\n",
        "def token_preds_to_spans(preds, offset_mapping, label_map, text):\n",
        "    \"\"\"\n",
        "    Converts token-level predictions to character spans.\n",
        "    Returns a list of {\"technique\": str, \"start\": int, \"end\": int}.\n",
        "    This improved version maintains separate active spans for each technique.\n",
        "    \"\"\"\n",
        "    spans = []\n",
        "    # Dictionary to keep current active span for each technique\n",
        "    current_spans = {}  # technique -> {\"start\": int, \"end\": int}\n",
        "    reversed_label_map = {v: k for k, v in label_map.items()}\n",
        "\n",
        "    # Iterate over each token with its offset mapping\n",
        "    for token_idx, (token_start, token_end) in enumerate(offset_mapping):\n",
        "        # Skip special tokens (e.g. [CLS], [SEP])\n",
        "        if token_start == 0 and token_end == 0:\n",
        "            continue\n",
        "\n",
        "        # Determine which techniques are predicted for this token\n",
        "        pred_class_indices = np.where(preds[token_idx] == 1)[0]\n",
        "        predicted_techniques = [reversed_label_map[c] for c in pred_class_indices]\n",
        "\n",
        "        # Flush active spans for techniques not predicted in the current token.\n",
        "        techniques_to_flush = []\n",
        "        for technique in current_spans:\n",
        "            if technique not in predicted_techniques:\n",
        "                spans.append({\n",
        "                    \"technique\": technique,\n",
        "                    \"start\": current_spans[technique][\"start\"],\n",
        "                    \"end\": current_spans[technique][\"end\"]\n",
        "                })\n",
        "                techniques_to_flush.append(technique)\n",
        "        for technique in techniques_to_flush:\n",
        "            del current_spans[technique]\n",
        "\n",
        "        # For each technique predicted in the current token, update or start a span.\n",
        "        for technique in predicted_techniques:\n",
        "            if technique in current_spans:\n",
        "                # If token_start exactly matches the end of the current span, extend it.\n",
        "                if token_start == current_spans[technique][\"end\"]:\n",
        "                    current_spans[technique][\"end\"] = token_end\n",
        "                else:\n",
        "                    # Otherwise, flush the current span and start a new one.\n",
        "                    spans.append({\n",
        "                        \"technique\": technique,\n",
        "                        \"start\": current_spans[technique][\"start\"],\n",
        "                        \"end\": current_spans[technique][\"end\"]\n",
        "                    })\n",
        "                    current_spans[technique] = {\"start\": token_start, \"end\": token_end}\n",
        "            else:\n",
        "                # Start a new span for this technique.\n",
        "                current_spans[technique] = {\"start\": token_start, \"end\": token_end}\n",
        "\n",
        "    # Flush any remaining active spans\n",
        "    for technique, span in current_spans.items():\n",
        "        spans.append({\n",
        "            \"technique\": technique,\n",
        "            \"start\": span[\"start\"],\n",
        "            \"end\": span[\"end\"]\n",
        "        })\n",
        "\n",
        "    # Merge overlapping spans per technique (if needed)\n",
        "    spans = merge_overlapping_spans(spans)\n",
        "    return spans\n",
        "\n",
        "def merge_overlapping_spans(spans):\n",
        "    \"\"\"Merge overlapping spans of the same technique\"\"\"\n",
        "    if not spans:\n",
        "        return []\n",
        "\n",
        "    # Sort by start position\n",
        "    spans.sort(key=lambda x: x[\"start\"])\n",
        "    merged = [spans[0]]\n",
        "\n",
        "    for current in spans[1:]:\n",
        "        last = merged[-1]\n",
        "        if (current[\"technique\"] == last[\"technique\"] and\n",
        "            current[\"start\"] <= last[\"end\"]):\n",
        "            # Merge overlapping spans\n",
        "            last[\"end\"] = max(last[\"end\"], current[\"end\"])\n",
        "        else:\n",
        "            merged.append(current)\n",
        "    return merged\n",
        "\n",
        "def predict_spans(model, tokenizer, text, label_map, thresholds, max_length=512):  # Add thresholds as argument\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    offset_mapping = encoding[\"offset_mapping\"][0].tolist()\n",
        "\n",
        "    # Run model inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoding.to(model.device))\n",
        "        logits = outputs.logits\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "    # Apply thresholds passed as argument\n",
        "    preds = np.zeros_like(probs)\n",
        "    for class_idx, thresh in thresholds.items():\n",
        "        preds[0, :, class_idx] = (probs[0, :, class_idx] > thresh).astype(int)\n",
        "\n",
        "    spans = token_preds_to_spans(preds, offset_mapping, label_map, text)\n",
        "    return spans\n",
        "\n",
        "def span_f1(true_spans, pred_spans):\n",
        "    # Convert spans to sets of tuples (technique, start, end)\n",
        "    true_set = set((s[\"technique\"], s[\"start\"], s[\"end\"]) for s in true_spans)\n",
        "    pred_set = set((s[\"technique\"], s[\"start\"], s[\"end\"]) for s in pred_spans)\n",
        "\n",
        "    tp = len(true_set & pred_set)\n",
        "    fp = len(pred_set - true_set)\n",
        "    fn = len(true_set - pred_set)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return {\"span_precision\": precision, \"span_recall\": recall, \"span_f1\": f1}\n",
        "\n",
        "def train_model(model_config, train_data, dev_data, label_map):\n",
        "    # Load model with 4-bit quantization\n",
        "    model, tokenizer = load_model_and_tokenizer(model_config)\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_processed = prepare_datasets(model_config, tokenizer, train_data)\n",
        "    dev_processed = prepare_datasets(model_config, tokenizer, dev_data)\n",
        "\n",
        "    train_dataset = MistralSpanDataset(\n",
        "    {\n",
        "        \"input_ids\": train_processed['encodings']['input_ids'],\n",
        "        \"attention_mask\": train_processed['encodings']['attention_mask']\n",
        "    },\n",
        "    labels=train_processed['labels']\n",
        ")\n",
        "\n",
        "    # Similarly for dev_dataset:\n",
        "    dev_dataset = MistralSpanDataset(\n",
        "        {\n",
        "            \"input_ids\": dev_processed['encodings']['input_ids'],\n",
        "            \"attention_mask\": dev_processed['encodings']['attention_mask']\n",
        "        },\n",
        "        labels=dev_processed['labels']\n",
        "    )\n",
        "\n",
        "    train_dataset_length = len(train_dataset)\n",
        "    gradient_accumulation = 4  # Match your gradient_accumulation_steps\n",
        "    max_steps = (train_dataset_length // (model_config[\"batch_size\"] * gradient_accumulation)) * NUM_EPOCHS\n",
        "\n",
        "    # Optimizer with gradient checkpointing\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        report_to=\"none\",\n",
        "        num_train_epochs=NUM_EPOCHS,\n",
        "        max_steps=max_steps,\n",
        "        per_device_train_batch_size=model_config[\"batch_size\"],\n",
        "        gradient_accumulation_steps=4,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        gradient_checkpointing=True,\n",
        "        logging_steps=10,\n",
        "        learning_rate=1e-4,\n",
        "        weight_decay=0.01,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        bf16=True,\n",
        "        fp16=False\n",
        "    )\n",
        "\n",
        "    class CustomTrainer(Trainer):\n",
        "        def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "            labels = inputs.pop(\"labels\")\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Masked loss calculation\n",
        "            active_loss = inputs[\"attention_mask\"].view(-1) == 1\n",
        "            active_logits = logits.view(-1, len(label_map))[active_loss]\n",
        "            active_labels = labels.view(-1, len(label_map))[active_loss]\n",
        "\n",
        "            loss = nn.BCEWithLogitsLoss()(active_logits, active_labels)\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=dev_dataset,\n",
        "        data_collator=mistral_collate_fn,\n",
        "        compute_metrics=lambda eval_pred: compute_metrics(eval_pred, label_map)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "    thresholds = eval_results[\"thresholds\"]\n",
        "\n",
        "    return model, thresholds\n",
        "\n",
        "def compute_metrics(eval_pred, label_map):\n",
        "    probs, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(probs)).numpy()\n",
        "    labels = labels.astype(np.float32)\n",
        "\n",
        "    best_thresholds = optimize_thresholds(probs, labels, label_map)\n",
        "\n",
        "    # Apply thresholds\n",
        "    preds = np.zeros_like(probs)\n",
        "    for class_idx, thresh in best_thresholds.items():\n",
        "        preds[:, :, class_idx] = (probs[:, :, class_idx] > thresh).astype(int)\n",
        "\n",
        "    # Flatten predictions and labels for metric calculation\n",
        "    flat_labels = labels.reshape(-1, len(label_map))\n",
        "    flat_preds = preds.reshape(-1, len(label_map))\n",
        "\n",
        "    micro_precision = precision_score(flat_labels, flat_preds, average=\"micro\", zero_division=0)\n",
        "    micro_recall = recall_score(flat_labels, flat_preds, average=\"micro\", zero_division=0)\n",
        "    micro_f1 = f1_score(flat_labels, flat_preds, average=\"micro\", zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"micro_precision\": micro_precision,\n",
        "        \"micro_recall\": micro_recall,\n",
        "        \"micro_f1\": micro_f1,\n",
        "        \"thresholds\": best_thresholds\n",
        "    }\n",
        "\n",
        "def load_data(file_path: str) -> list:\n",
        "    with open(data_dir + file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def prepare_datasets(config: dict, tokenizer, data):\n",
        "    processed = {\n",
        "        \"encodings\": {\"input_ids\": [], \"attention_mask\": []},\n",
        "        \"labels\": [],\n",
        "        \"offset_mappings\": []\n",
        "    }\n",
        "    max_length = config[\"max_length\"]\n",
        "\n",
        "    for item in data:\n",
        "        encoding = tokenizer(\n",
        "            item[\"text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_offsets_mapping=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        labels = convert_spans_to_token_labels(\n",
        "            item[\"text\"],\n",
        "            item.get(\"labels\", []),\n",
        "            encoding[\"offset_mapping\"][0].tolist(),\n",
        "            max_length,\n",
        "            label_map\n",
        "        )\n",
        "\n",
        "        # Store input_ids and attention_mask under \"encodings\"\n",
        "        processed[\"encodings\"][\"input_ids\"].append(encoding[\"input_ids\"][0])\n",
        "        processed[\"encodings\"][\"attention_mask\"].append(encoding[\"attention_mask\"][0])\n",
        "        processed[\"labels\"].append(torch.FloatTensor(labels))\n",
        "        processed[\"offset_mappings\"].append(encoding[\"offset_mapping\"][0])\n",
        "\n",
        "    # Stack encodings\n",
        "    processed[\"encodings\"][\"input_ids\"] = torch.stack(processed[\"encodings\"][\"input_ids\"])\n",
        "    processed[\"encodings\"][\"attention_mask\"] = torch.stack(processed[\"encodings\"][\"attention_mask\"])\n",
        "\n",
        "    return {\n",
        "        \"encodings\": processed[\"encodings\"],\n",
        "        \"labels\": torch.stack(processed[\"labels\"]),\n",
        "        \"offset_mappings\": processed[\"offset_mappings\"]  # Plural\n",
        "    }\n",
        "\n",
        "# Add data loading and label map creation BEFORE training\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = \"/content/drive/My Drive/SEMEVAL/data/\"\n",
        "\n",
        "# Load datasets\n",
        "train_data = load_data(\"training_set_task2.txt\")\n",
        "dev_data = load_data(\"dev_set_task2.txt\")\n",
        "\n",
        "# Create label map\n",
        "all_techniques = sorted({\n",
        "    label[\"technique\"].strip().lower() for item in train_data + dev_data\n",
        "    for label in item.get(\"labels\", [])\n",
        "})\n",
        "label_map = {tech: idx for idx, tech in enumerate(all_techniques)}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Now run the training\n",
        "NUM_EPOCHS = 10\n",
        "MODEL_TO_TRAIN = \"mistral-7b\"\n",
        "\n",
        "print(f\"Training {MODEL_TO_TRAIN}...\")\n",
        "best_model, thresholds = train_model(\n",
        "    MODEL_CONFIGS[MODEL_TO_TRAIN],\n",
        "    train_data,\n",
        "    dev_data,\n",
        "    label_map\n",
        ")"
      ],
      "metadata": {
        "id": "88-LcOVk58Gc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}